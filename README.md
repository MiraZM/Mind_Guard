#Mind Guard: AI-Powered Suicide Ideation Detection
Introduction
Mind Guard is a machine learning project aimed at identifying suicidal ideation in textual data. Utilizing a pre-trained BERT model, this project demonstrates the potential of AI in supporting early intervention and prevention efforts in mental health.

#Project Overview
Objective: To develop a BERT-based classifier for detecting subtle cues of suicidal ideation in text.
Dataset: The project uses a 6000-line dataset curated from diverse online platforms, annotated by experienced psychologists.
Methodology: Includes data preprocessing, model fine-tuning, hyperparameter optimization, and comprehensive validation.
#Model Architecture
BERT-Based Classifier: Leveraging BERT-base-uncased for nuanced understanding of text.
Fine-Tuning: The model is fine-tuned on the annotated dataset, focusing on suicide prevention.
Hyperparameter Optimization: Employing grid search to determine optimal learning rate, batch size, and training epochs.
#Evaluation and Validation
Metrics: Model performance evaluated using accuracy, precision, recall, and F1-score.
Qualitative Analysis: Conducted to understand the modelâ€™s decision-making process.
#Results
Achieved high validation accuracy, precision, recall, and F1-score, indicating the model's effectiveness in identifying suicidal intent.
Key insights highlight the model's potential as a tool for early identification of at-risk individuals.
#Limitations and Future Directions
Expanding the dataset size and diversity for enhanced generalizability.
Exploring alternative model architectures and feature engineering.
#Tools and Libraries Used
Google Colab: For GPU-powered training.
PyTorch: Primary library for model building and training.
Transformers Library: For BERT model implementation.
Pandas, NumPy, Matplotlib: For data analysis and visualization.
scikit-learn: For data preprocessing and model evaluation.
#How to Use
Instructions for setting up the environment, loading the dataset, training the model, and conducting evaluations.
#Authors and Acknowledgments
Team: [Maha Al-Hayajneh Mira Melhem Mirna AbuDhaim Wasan Hawari]
Supervision: Dr. Tamam al Sarhan, University of Jordan.
Acknowledgments: Special thanks to all contributors and supporters of this project.
